{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b7a0dc",
   "metadata": {},
   "source": [
    "# YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71426e14",
   "metadata": {},
   "source": [
    "## Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Conv+BN+SiLU 블록\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, c1, c2, k=3, s=1, p=None):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, k // 2 if p is None else p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.SiLU()  # Swish\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "# C2f (Cross Stage Partial Fusion)\n",
    "class C2f(nn.Module):\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, e=0.5):\n",
    "        super().__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        self.cv1 = Conv(c1, 2 * c_, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * c_, c2, 1)\n",
    "        self.m = nn.ModuleList([Bottleneck(c_, c_) for _ in range(n)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = list(self.cv1(x).chunk(2, 1))\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "\n",
    "# Bottleneck 블록 (C2f 내부)\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, c1, c2, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.cv1 = Conv(c1, c2, 1, 1)\n",
    "        self.cv2 = Conv(c2, c2, 3, 1)\n",
    "        self.add = shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cv2(self.cv1(x))\n",
    "        return out + x if self.add else out\n",
    "\n",
    "# SPPF\n",
    "class SPPF(nn.Module):\n",
    "    def __init__(self, c1, c2, k=5):\n",
    "        super().__init__()\n",
    "        self.cv1 = Conv(c1, c2, 1, 1)\n",
    "        self.cv2 = Conv(c2 * 4, c2, 1, 1)\n",
    "        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cv1(x)\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        y3 = self.m(y2)\n",
    "        return self.cv2(torch.cat([x, y1, y2, y3], 1))\n",
    "\n",
    "# YOLOv8 Backbone 예시\n",
    "class YOLOv8Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = Conv(3, 32, 3, 2)\n",
    "        self.stage1 = C2f(32, 64, n=1)\n",
    "        self.stage2 = C2f(64, 128, n=2)\n",
    "        self.stage3 = C2f(128, 256, n=3)\n",
    "        self.sppf = SPPF(256, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.sppf(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2eb37c",
   "metadata": {},
   "source": [
    "## Neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(nn.Module):\n",
    "    def __init__(self, channels=[256, 512, 1024]):  # 입력 feature의 채널 수 예시\n",
    "        super().__init__()\n",
    "        # Upsample, concat, C2f 등을 위한 레이어 정의\n",
    "        self.reduce_conv1 = nn.Conv2d(channels[2], channels[1], 1)  # 1024→512\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c2f1 = C2f(channels[1]*2, channels[1], n=3)  # Concat(512+512)→512\n",
    "        \n",
    "        self.reduce_conv2 = nn.Conv2d(channels[1], channels[0], 1)  # 512→256\n",
    "        self.c2f2 = C2f(channels[0]*2, channels[0], n=3)  # Concat(256+256)→256\n",
    "        \n",
    "        # Downsample (PAN), for bottom-up path\n",
    "        self.downsample1 = nn.Conv2d(channels[0], channels[0], 3, stride=2, padding=1)\n",
    "        self.c2f3 = C2f(channels[0]*2, channels[1], n=3)  # (256+256)→512\n",
    "\n",
    "        self.downsample2 = nn.Conv2d(channels[1], channels[1], 3, stride=2, padding=1)\n",
    "        self.c2f4 = C2f(channels[1]*2, channels[2], n=3)  # (512+512)→1024\n",
    "\n",
    "    def forward(self, features):\n",
    "        # features: [P3, P4, P5] (예: [256, 512, 1024])\n",
    "        P3, P4, P5 = features\n",
    "        \n",
    "        # FPN top-down\n",
    "        x = self.reduce_conv1(P5)  # 1024→512\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, P4], dim=1)  # (512+512)\n",
    "        x = self.c2f1(x)\n",
    "        \n",
    "        y = self.reduce_conv2(x)\n",
    "        y = self.upsample(y)\n",
    "        y = torch.cat([y, P3], dim=1)\n",
    "        y = self.c2f2(y)  # 최상위 해상도 feature\n",
    "        \n",
    "        # PAN bottom-up\n",
    "        z = self.downsample1(y)\n",
    "        z = torch.cat([z, x], dim=1)\n",
    "        z = self.c2f3(z)\n",
    "        \n",
    "        w = self.downsample2(z)\n",
    "        w = torch.cat([w, P5], dim=1)\n",
    "        w = self.c2f4(w)\n",
    "        \n",
    "        # 최종적으로 [y, z, w] 등 여러 해상도 feature 반환 (head에서 사용)\n",
    "        return [y, z, w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b5898",
   "metadata": {},
   "source": [
    "## Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectPoseHead(nn.Module):\n",
    "    def __init__(self, num_classes, num_keypoints, ch):  # ch: neck에서 들어오는 각 feature의 채널 수\n",
    "        super().__init__()\n",
    "        # 각 scale(feature map)별로 별도의 head 사용\n",
    "        self.detect_layers = nn.ModuleList([\n",
    "            nn.Conv2d(c, (num_classes + 4 + num_keypoints*3), 1) for c in ch\n",
    "        ])\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # features: neck output, list of [P3, P4, P5]\n",
    "        outputs = []\n",
    "        for x, head in zip(features, self.detect_layers):\n",
    "            y = head(x)  # [B, out_dim, H, W]\n",
    "            # [B, 4+num_classes+num_keypoints*3, H, W]\n",
    "            outputs.append(y)\n",
    "        return outputs  # [P3_out, P4_out, P5_out]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fdb14",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e249ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def yolo_pose_loss(\n",
    "    pred,              # [B, A, H, W, 4+C+K*3] or [B, N, 4+C+K*3] (after flatten)\n",
    "    target,            # GT dict with keys: 'boxes', 'classes', 'objectness', 'keypoints', 'kp_vis'\n",
    "    num_classes,\n",
    "    num_keypoints,\n",
    "    box_weight=7.5,    # Default YOLOv8: box loss weight\n",
    "    cls_weight=0.5,    # class loss weight\n",
    "    obj_weight=1.0,    # objectness loss weight\n",
    "    kpt_weight=1.5,    # keypoint loss weight\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    pred: [B, N, 4+C+K*3]\n",
    "    target: {\n",
    "        'boxes': [B, N, 4],      # (x, y, w, h) normalized\n",
    "        'classes': [B, N],       # class idx\n",
    "        'objectness': [B, N],    # 1 if object, else 0\n",
    "        'keypoints': [B, N, K, 2],  # GT (x, y) for each keypoint (normalized)\n",
    "        'kp_vis': [B, N, K],     # 1 if visible, 0 if not\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Objectness Loss (BCE)\n",
    "    obj_pred = pred[..., 4]\n",
    "    obj_gt = target['objectness'].float().to(device)\n",
    "    obj_loss = F.binary_cross_entropy_with_logits(obj_pred, obj_gt, reduction='mean')\n",
    "\n",
    "    # 2. Box Regression Loss (CIoU or GIoU, here just SmoothL1 for simplicity)\n",
    "    box_pred = pred[..., :4]\n",
    "    box_gt = target['boxes'].to(device)\n",
    "    box_loss = F.smooth_l1_loss(box_pred, box_gt, reduction='none')    # [B, N, 4]\n",
    "    box_loss = box_loss.mean(-1)                                      # [B, N]\n",
    "    box_loss = (box_loss * obj_gt).sum() / (obj_gt.sum() + 1e-8)      # Only for positive anchors\n",
    "\n",
    "    # 3. Classification Loss (BCE for multi-label, CE for single-label)\n",
    "    class_pred = pred[..., 5:5+num_classes]                           # [B, N, C]\n",
    "    class_gt = F.one_hot(target['classes'].long(), num_classes).float().to(device)   # [B, N, C]\n",
    "    class_loss = F.binary_cross_entropy_with_logits(class_pred, class_gt, reduction='none')  # [B, N, C]\n",
    "    class_loss = (class_loss.mean(-1) * obj_gt).sum() / (obj_gt.sum() + 1e-8)       # Only for objects\n",
    "\n",
    "    # 4. Keypoint Loss (SmoothL1 for (x, y), BCE for conf)\n",
    "    start = 5 + num_classes\n",
    "    kpt_pred = pred[..., start:].reshape(*pred.shape[:-1], num_keypoints, 3)         # [B, N, K, 3]\n",
    "    kpt_gt = target['keypoints'].to(device)                                          # [B, N, K, 2]\n",
    "    kpt_vis = target['kp_vis'].float().to(device)                                    # [B, N, K]\n",
    "\n",
    "    # (x, y) loss\n",
    "    xy_loss = F.smooth_l1_loss(kpt_pred[..., :2], kpt_gt, reduction='none').sum(-1)  # [B, N, K]\n",
    "    xy_loss = (xy_loss * kpt_vis * obj_gt.unsqueeze(-1)).sum() / ((kpt_vis * obj_gt.unsqueeze(-1)).sum() + 1e-8)\n",
    "\n",
    "    # conf loss (confidence: visible or not)\n",
    "    conf_pred = kpt_pred[..., 2]\n",
    "    conf_gt = kpt_vis\n",
    "    conf_loss = F.binary_cross_entropy_with_logits(conf_pred, conf_gt, reduction='none')  # [B, N, K]\n",
    "    conf_loss = (conf_loss * obj_gt.unsqueeze(-1)).sum() / ((kpt_vis * obj_gt.unsqueeze(-1)).sum() + 1e-8)\n",
    "\n",
    "    kpt_loss = xy_loss + 0.5 * conf_loss   # 0.5는 공식 코드 기준, 조정 가능\n",
    "\n",
    "    # 총합\n",
    "    total_loss = (\n",
    "        box_weight * box_loss +\n",
    "        cls_weight * class_loss +\n",
    "        obj_weight * obj_loss +\n",
    "        kpt_weight * kpt_loss\n",
    "    )\n",
    "\n",
    "    # (optionally) 개별 loss 값도 return\n",
    "    return total_loss, {\n",
    "        \"box_loss\": box_loss.item(),\n",
    "        \"obj_loss\": obj_loss.item(),\n",
    "        \"class_loss\": class_loss.item(),\n",
    "        \"kpt_loss\": kpt_loss.item()\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
